{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d90a887",
   "metadata": {},
   "source": [
    "# **Проект \"Рыночная стоимость авто\"**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b315bb",
   "metadata": {},
   "source": [
    "Сервис по продаже автомобилей с пробегом «Не бит, не крашен» разрабатывает приложение для привлечения новых клиентов. В нём можно быстро узнать рыночную стоимость своего автомобиля. В нашем распоряжении исторические данные: технические характеристики, комплектации и цены автомобилей."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af1c539",
   "metadata": {},
   "source": [
    "# **1. Вводная информация**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5179e656",
   "metadata": {},
   "source": [
    "## **1.1. Задача**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6648df6e",
   "metadata": {},
   "source": [
    "Нам нужно построить модель для определения стоимости авто. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97fa1c86",
   "metadata": {},
   "source": [
    "**Заказчику важны:**\n",
    "- качество предсказания;\n",
    "- скорость предсказания;\n",
    "- время обучения."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611096d1",
   "metadata": {},
   "source": [
    "## **1.2. Описание набора данных**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d983bec",
   "metadata": {},
   "source": [
    "**Признаки:**\n",
    "- `DateCrawled` — дата скачивания анкеты из базы\n",
    "- `VehicleType` — тип автомобильного кузова\n",
    "- `RegistrationYear` — год регистрации автомобиля\n",
    "- `Gearbox` — тип коробки передач\n",
    "- `Power` — мощность (л. с.)\n",
    "- `Model` — модель автомобиля\n",
    "- `Kilometer` — пробег (км)\n",
    "- `RegistrationMonth` — месяц регистрации автомобиля\n",
    "- `FuelType` — тип топлива\n",
    "- `Brand` — марка автомобиля\n",
    "- `NotRepaired` — была машина в ремонте или нет\n",
    "- `DateCreated` — дата создания анкеты\n",
    "- `NumberOfPictures` — количество фотографий автомобиля\n",
    "- `PostalCode` — почтовый индекс владельца анкеты (пользователя)\n",
    "- `LastSeen` — дата последней активности пользователя\n",
    "\n",
    "**Целевой признак:**\n",
    "- `Price` — цена (евро)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279fce89",
   "metadata": {},
   "source": [
    "## **1.3. План работы**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7187d1c5",
   "metadata": {},
   "source": [
    "Коротко опишем наш пайплайн работы:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46ef600",
   "metadata": {},
   "source": [
    "1. Загрузим и познакомимся с данными, оценим их качество и состояние;\n",
    "2. Выполним необходимую предобработу данных;\n",
    "3. Определим явные и скрытые взаимосвязи;\n",
    "4. Определим признаки, которые лучше всего подходят для обучения;\n",
    "5. Определим сетку параметров для поиска наиболее удачной модели;\n",
    "6. Предварительное обучение и подбор параметров произведем для начала на небольшом количестве данных;\n",
    "7. Проверим два основных варианта модели линейной регрессии и градиентного бустинга (LightGBM), а также ряд дополнительных моделей с улучшениями на основе этих. Чтобы усилить исследование, не ограничимся градиентным бустингом. Попробуйте более простые модели — иногда они работают лучше. Это редкие случаи, которые легко пропустить, если всегда применять только бустинг.\n",
    "8. Проанализируем и сравним характеристики моделей: точность предсказания, скорость работы и качество моделей.\n",
    "\n",
    "Выбранная метрика для оценки качества: `RMSE`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a556b77f",
   "metadata": {},
   "source": [
    "# **2. Настройка рабочего пространства**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2842e01",
   "metadata": {},
   "source": [
    "## **2.1. Импорт библиотек и настройка рабочего пространства.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2f35af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML \n",
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from typing import List, Any, Callable, Dict, Optional, Union\n",
    "\n",
    "from phik import phik_matrix\n",
    "\n",
    "from scipy.stats import ttest_ind, levene, bartlett, fligner\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.model_selection import GridSearchCV, KFold, StratifiedKFold, train_test_split\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, mutual_info_classif\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, MaxAbsScaler, OneHotEncoder, StandardScaler, OrdinalEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import recall_score, f1_score, precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b0be2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore') # чтобы не было красный полей с предупреждениями об устаревших библиотеках\n",
    "# %matplotlib inline\n",
    "plt.ion() # принудительное отображение графиков matplotlib в VS Code\n",
    "pd.set_option(\"display.max_columns\", None) # чтобы сам df был пошире\n",
    "pd.set_option('display.max_colwidth', None) # чтобы df колонки были пошире\n",
    "pd.set_option('display.float_format', '{:.3f}'.format) # округление чисел в df, чтобы числа не печатал экспоненциально\n",
    "pd.options.display.expand_frame_repr = False # для принта чтобы колонки не переносил рабоатет тольок в vs code, in jupyter notebook получается каша"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f47fc93",
   "metadata": {},
   "source": [
    "## **2.2. Загрузка данных**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec4356c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Данные загружены с домашнего компьютера\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    df = pd.read_csv('datasets/autos.csv')\n",
    "    print(\"Данные загружены с домашнего компьютера\")\n",
    "except (FileNotFoundError, OSError):\n",
    "    # Альтернативный путь для запуска из Интернета\n",
    "    df = pd.read_csv('/datasets/autos.csv')\n",
    "    print(\"Данные загружены из Интернета\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb922b97",
   "metadata": {},
   "source": [
    "# **3. EDA: исследовательский анализ данных**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0706a9",
   "metadata": {},
   "source": [
    "# **3.1. Оценка качества представленных данных**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb87a941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 354369 entries, 0 to 354368\n",
      "Data columns (total 16 columns):\n",
      " #   Column             Non-Null Count   Dtype \n",
      "---  ------             --------------   ----- \n",
      " 0   DateCrawled        354369 non-null  object\n",
      " 1   Price              354369 non-null  int64 \n",
      " 2   VehicleType        316879 non-null  object\n",
      " 3   RegistrationYear   354369 non-null  int64 \n",
      " 4   Gearbox            334536 non-null  object\n",
      " 5   Power              354369 non-null  int64 \n",
      " 6   Model              334664 non-null  object\n",
      " 7   Kilometer          354369 non-null  int64 \n",
      " 8   RegistrationMonth  354369 non-null  int64 \n",
      " 9   FuelType           321474 non-null  object\n",
      " 10  Brand              354369 non-null  object\n",
      " 11  Repaired           283215 non-null  object\n",
      " 12  DateCreated        354369 non-null  object\n",
      " 13  NumberOfPictures   354369 non-null  int64 \n",
      " 14  PostalCode         354369 non-null  int64 \n",
      " 15  LastSeen           354369 non-null  object\n",
      "dtypes: int64(7), object(9)\n",
      "memory usage: 43.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "afbbe2dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DateCrawled</th>\n",
       "      <th>Price</th>\n",
       "      <th>VehicleType</th>\n",
       "      <th>RegistrationYear</th>\n",
       "      <th>Gearbox</th>\n",
       "      <th>Power</th>\n",
       "      <th>Model</th>\n",
       "      <th>Kilometer</th>\n",
       "      <th>RegistrationMonth</th>\n",
       "      <th>FuelType</th>\n",
       "      <th>Brand</th>\n",
       "      <th>Repaired</th>\n",
       "      <th>DateCreated</th>\n",
       "      <th>NumberOfPictures</th>\n",
       "      <th>PostalCode</th>\n",
       "      <th>LastSeen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-03-24 11:52:17</td>\n",
       "      <td>480</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1993</td>\n",
       "      <td>manual</td>\n",
       "      <td>0</td>\n",
       "      <td>golf</td>\n",
       "      <td>150000</td>\n",
       "      <td>0</td>\n",
       "      <td>petrol</td>\n",
       "      <td>volkswagen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-03-24 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>70435</td>\n",
       "      <td>2016-04-07 03:16:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-03-24 10:58:45</td>\n",
       "      <td>18300</td>\n",
       "      <td>coupe</td>\n",
       "      <td>2011</td>\n",
       "      <td>manual</td>\n",
       "      <td>190</td>\n",
       "      <td>NaN</td>\n",
       "      <td>125000</td>\n",
       "      <td>5</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>audi</td>\n",
       "      <td>yes</td>\n",
       "      <td>2016-03-24 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>66954</td>\n",
       "      <td>2016-04-07 01:46:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-03-14 12:52:21</td>\n",
       "      <td>9800</td>\n",
       "      <td>suv</td>\n",
       "      <td>2004</td>\n",
       "      <td>auto</td>\n",
       "      <td>163</td>\n",
       "      <td>grand</td>\n",
       "      <td>125000</td>\n",
       "      <td>8</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>jeep</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-03-14 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>90480</td>\n",
       "      <td>2016-04-05 12:47:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-03-17 16:54:04</td>\n",
       "      <td>1500</td>\n",
       "      <td>small</td>\n",
       "      <td>2001</td>\n",
       "      <td>manual</td>\n",
       "      <td>75</td>\n",
       "      <td>golf</td>\n",
       "      <td>150000</td>\n",
       "      <td>6</td>\n",
       "      <td>petrol</td>\n",
       "      <td>volkswagen</td>\n",
       "      <td>no</td>\n",
       "      <td>2016-03-17 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>91074</td>\n",
       "      <td>2016-03-17 17:40:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-03-31 17:25:20</td>\n",
       "      <td>3600</td>\n",
       "      <td>small</td>\n",
       "      <td>2008</td>\n",
       "      <td>manual</td>\n",
       "      <td>69</td>\n",
       "      <td>fabia</td>\n",
       "      <td>90000</td>\n",
       "      <td>7</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>skoda</td>\n",
       "      <td>no</td>\n",
       "      <td>2016-03-31 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>60437</td>\n",
       "      <td>2016-04-06 10:17:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354364</th>\n",
       "      <td>2016-03-21 09:50:58</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2005</td>\n",
       "      <td>manual</td>\n",
       "      <td>0</td>\n",
       "      <td>colt</td>\n",
       "      <td>150000</td>\n",
       "      <td>7</td>\n",
       "      <td>petrol</td>\n",
       "      <td>mitsubishi</td>\n",
       "      <td>yes</td>\n",
       "      <td>2016-03-21 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>2694</td>\n",
       "      <td>2016-03-21 10:42:49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354365</th>\n",
       "      <td>2016-03-14 17:48:27</td>\n",
       "      <td>2200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2005</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sonstige_autos</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-03-14 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>39576</td>\n",
       "      <td>2016-04-06 00:46:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354366</th>\n",
       "      <td>2016-03-05 19:56:21</td>\n",
       "      <td>1199</td>\n",
       "      <td>convertible</td>\n",
       "      <td>2000</td>\n",
       "      <td>auto</td>\n",
       "      <td>101</td>\n",
       "      <td>fortwo</td>\n",
       "      <td>125000</td>\n",
       "      <td>3</td>\n",
       "      <td>petrol</td>\n",
       "      <td>smart</td>\n",
       "      <td>no</td>\n",
       "      <td>2016-03-05 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>26135</td>\n",
       "      <td>2016-03-11 18:17:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354367</th>\n",
       "      <td>2016-03-19 18:57:12</td>\n",
       "      <td>9200</td>\n",
       "      <td>bus</td>\n",
       "      <td>1996</td>\n",
       "      <td>manual</td>\n",
       "      <td>102</td>\n",
       "      <td>transporter</td>\n",
       "      <td>150000</td>\n",
       "      <td>3</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>volkswagen</td>\n",
       "      <td>no</td>\n",
       "      <td>2016-03-19 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>87439</td>\n",
       "      <td>2016-04-07 07:15:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354368</th>\n",
       "      <td>2016-03-20 19:41:08</td>\n",
       "      <td>3400</td>\n",
       "      <td>wagon</td>\n",
       "      <td>2002</td>\n",
       "      <td>manual</td>\n",
       "      <td>100</td>\n",
       "      <td>golf</td>\n",
       "      <td>150000</td>\n",
       "      <td>6</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>volkswagen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-03-20 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>40764</td>\n",
       "      <td>2016-03-24 12:45:21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>354369 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                DateCrawled  Price  VehicleType  RegistrationYear Gearbox  Power        Model  Kilometer  RegistrationMonth  FuelType           Brand Repaired          DateCreated  NumberOfPictures  PostalCode             LastSeen\n",
       "0       2016-03-24 11:52:17    480          NaN              1993  manual      0         golf     150000                  0    petrol      volkswagen      NaN  2016-03-24 00:00:00                 0       70435  2016-04-07 03:16:57\n",
       "1       2016-03-24 10:58:45  18300        coupe              2011  manual    190          NaN     125000                  5  gasoline            audi      yes  2016-03-24 00:00:00                 0       66954  2016-04-07 01:46:50\n",
       "2       2016-03-14 12:52:21   9800          suv              2004    auto    163        grand     125000                  8  gasoline            jeep      NaN  2016-03-14 00:00:00                 0       90480  2016-04-05 12:47:46\n",
       "3       2016-03-17 16:54:04   1500        small              2001  manual     75         golf     150000                  6    petrol      volkswagen       no  2016-03-17 00:00:00                 0       91074  2016-03-17 17:40:17\n",
       "4       2016-03-31 17:25:20   3600        small              2008  manual     69        fabia      90000                  7  gasoline           skoda       no  2016-03-31 00:00:00                 0       60437  2016-04-06 10:17:21\n",
       "...                     ...    ...          ...               ...     ...    ...          ...        ...                ...       ...             ...      ...                  ...               ...         ...                  ...\n",
       "354364  2016-03-21 09:50:58      0          NaN              2005  manual      0         colt     150000                  7    petrol      mitsubishi      yes  2016-03-21 00:00:00                 0        2694  2016-03-21 10:42:49\n",
       "354365  2016-03-14 17:48:27   2200          NaN              2005     NaN      0          NaN      20000                  1       NaN  sonstige_autos      NaN  2016-03-14 00:00:00                 0       39576  2016-04-06 00:46:52\n",
       "354366  2016-03-05 19:56:21   1199  convertible              2000    auto    101       fortwo     125000                  3    petrol           smart       no  2016-03-05 00:00:00                 0       26135  2016-03-11 18:17:12\n",
       "354367  2016-03-19 18:57:12   9200          bus              1996  manual    102  transporter     150000                  3  gasoline      volkswagen       no  2016-03-19 00:00:00                 0       87439  2016-04-07 07:15:26\n",
       "354368  2016-03-20 19:41:08   3400        wagon              2002  manual    100         golf     150000                  6  gasoline      volkswagen      NaN  2016-03-20 00:00:00                 0       40764  2016-03-24 12:45:21\n",
       "\n",
       "[354369 rows x 16 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c91f64d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>RegistrationYear</th>\n",
       "      <th>Power</th>\n",
       "      <th>Kilometer</th>\n",
       "      <th>RegistrationMonth</th>\n",
       "      <th>NumberOfPictures</th>\n",
       "      <th>PostalCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>354369.000</td>\n",
       "      <td>354369.000</td>\n",
       "      <td>354369.000</td>\n",
       "      <td>354369.000</td>\n",
       "      <td>354369.000</td>\n",
       "      <td>354369.000</td>\n",
       "      <td>354369.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4416.657</td>\n",
       "      <td>2004.234</td>\n",
       "      <td>110.094</td>\n",
       "      <td>128211.173</td>\n",
       "      <td>5.715</td>\n",
       "      <td>0.000</td>\n",
       "      <td>50508.689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4514.159</td>\n",
       "      <td>90.228</td>\n",
       "      <td>189.850</td>\n",
       "      <td>37905.342</td>\n",
       "      <td>3.726</td>\n",
       "      <td>0.000</td>\n",
       "      <td>25783.096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000</td>\n",
       "      <td>1000.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>5000.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1067.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1050.000</td>\n",
       "      <td>1999.000</td>\n",
       "      <td>69.000</td>\n",
       "      <td>125000.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>30165.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2700.000</td>\n",
       "      <td>2003.000</td>\n",
       "      <td>105.000</td>\n",
       "      <td>150000.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>49413.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6400.000</td>\n",
       "      <td>2008.000</td>\n",
       "      <td>143.000</td>\n",
       "      <td>150000.000</td>\n",
       "      <td>9.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>71083.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>20000.000</td>\n",
       "      <td>9999.000</td>\n",
       "      <td>20000.000</td>\n",
       "      <td>150000.000</td>\n",
       "      <td>12.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>99998.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Price  RegistrationYear      Power  Kilometer  RegistrationMonth  NumberOfPictures  PostalCode\n",
       "count 354369.000        354369.000 354369.000 354369.000         354369.000        354369.000  354369.000\n",
       "mean    4416.657          2004.234    110.094 128211.173              5.715             0.000   50508.689\n",
       "std     4514.159            90.228    189.850  37905.342              3.726             0.000   25783.096\n",
       "min        0.000          1000.000      0.000   5000.000              0.000             0.000    1067.000\n",
       "25%     1050.000          1999.000     69.000 125000.000              3.000             0.000   30165.000\n",
       "50%     2700.000          2003.000    105.000 150000.000              6.000             0.000   49413.000\n",
       "75%     6400.000          2008.000    143.000 150000.000              9.000             0.000   71083.000\n",
       "max    20000.000          9999.000  20000.000 150000.000             12.000             0.000   99998.000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8948047",
   "metadata": {},
   "source": [
    "## **3.2. Вывод о качестве данных**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08794d29",
   "metadata": {},
   "source": [
    "**Качество данных УДОВЛЕТВОРИТЕЛЬНОЕ с серьезными проблемами**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a338a4cd",
   "metadata": {},
   "source": [
    "**1. Аномальные значения и подозрительные значения:**\n",
    "\n",
    "`Price`:  min=0, max=20000 (цена 0€ — явная ошибка)\n",
    "\n",
    "`Power`: min=0, max=20000 (мощность 0 и 20000 л.с. — нереально)\n",
    "\n",
    "`RegistrationYear`: min=1000, max=9999 (автомобили из 1000 и 9999 года — ошибка), двузначные отображения года (90), вероятно, тоже требуют внимания и коррекции.\n",
    "\n",
    "`RegistrationMonth`: min=0 (месяц 0 не существует)\n",
    "\n",
    "`Kilometer`: 75% значений = 150000 км (округление/ограничение)\n",
    "\n",
    "`NumberOfPictures`: все значения = 0 (признак бесполезен)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbcaeec8",
   "metadata": {},
   "source": [
    "**2. Пропуски данных:**\n",
    "\n",
    "`VehicleType`: 37490 пропусков (10.6%)\n",
    "\n",
    "`Gearbox`: 19833 пропусков (5.6%)\n",
    "\n",
    "`Model`: 19705 пропусков (5.6%)\n",
    "\n",
    "`FuelType`: 32895 пропусков (9.3%)\n",
    "\n",
    "`Repaired`: 71154 пропусков (20.1%) — критично!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9561a3",
   "metadata": {},
   "source": [
    "**3. Несогласованность:**\n",
    "\n",
    "`Repaired` в датасете, но в описании `NotRepaired` (ПОЧЕМУ? инверсия логики?)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427fa490",
   "metadata": {},
   "source": [
    "**Необходимые действия:**\n",
    "\n",
    "- Удалить аномалии (Price=0, Power=0/20000, Year<1900/>2016)\n",
    "\n",
    "- Обработать пропуски (заполнение средним / удаление - проверить изменение качества модели)\n",
    "\n",
    "- Проверить логику Repaired\n",
    "\n",
    "- Исследовать распределение Kilometer\n",
    "\n",
    "- Удалить `NumberOfPictures` (нулевая вариативность) и `DateCrawled`, `DateCreated`, `LastSeen` (технические даты)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c1f3e6",
   "metadata": {},
   "source": [
    "**Вывод:** Данные требуют серьезной предобработки перед обучением модели."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3569de73",
   "metadata": {},
   "source": [
    "## **3.3. Создание pipeline для предобработки**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737c4c73",
   "metadata": {},
   "source": [
    "\n",
    "Мы планируем использовать два варианта модели, в связи с чем будет отличать немного процесс предобработки.\n",
    "\n",
    "- LinearRegression: нужна стандартизация (StandardScaler)\n",
    "\n",
    "- LightGBM: стандартизация не нужна"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5949b878",
   "metadata": {},
   "source": [
    "Произведем предобработку данных на классах в PipeLine. Для этого создадим следующие классы:\n",
    "- `MistakeCorrector` - для исправления некорректного отображения данных, например, когда все числа в столбце нужно умножить на 100;\n",
    "- `DecimalPointChanger` - проверяет каждое значение столбца на наличие правильного разделителя дроби, в случае если будет найдена запята - заменит ее на точку;\n",
    "- `OutlierRemover` - удалить выбросы только в разрешенных столбцах на основе списка столбцов;\n",
    "- `ImplicitDuplicatesViewer` - отобразит список уникальных нечисловых значений каждого столбца, что должно помочь опредлелить неявные дубликаты в столбцах;\n",
    "- `DuplicateRemover` - удалит явные дубликаты;\n",
    "- `MissingValueHandler` - обрабатывает пропуски на основе выбранной стратегии, по умолчанию, удаляет всю строку, если есть в ней пропуск;\n",
    "- `ColumnRemover` - удаляет лишний столбцы из датафрейма;\n",
    "- `FloatToIntChanger` - преобразует дробное число в целочисленное.\n",
    "\n",
    "Эти классы мы передадим в класс `EDAPreprocessor`, который станет основной состаляющей пайплайна EDA_Preprocessor_pipline, который будет производить предобработку данных. Зпуск пайплайна буддет вызываться функией  `run_preprocessor()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7c5ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MistakeCorrector(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Класс для исправления ошибок в данных. Принимает опционально словарь с правильными значениями, список колонок, а также прямое указания действия в виде lambda функции.\"\"\"\n",
    "    def __init__(\n",
    "            self, \n",
    "            columns: List[str], \n",
    "            values_dict: Optional[Dict[Any, Any]] = None, \n",
    "            func: Optional[Callable] = None,\n",
    "            strategy: str = 'dict'\n",
    "            ):\n",
    "        \n",
    "        \"\"\"\n",
    "        Инициализация исправителя ошибок.\n",
    "        \n",
    "        Parameters:\n",
    "        - columns: список столбцов для обработки (обязательный)\n",
    "        - values_dict: словарь {некорректное_значение: корректное_значение} (опционально)\n",
    "        - func: функция для преобразования значений (например, lambda x: x * 10) (опционально)\n",
    "        - strategy: стратегия обработки ('dict' или 'func'), по умолчанию 'dict'.\n",
    "        \"\"\"\n",
    "\n",
    "        if not columns:\n",
    "            raise ValueError(\"Параметр 'columns' не может быть пустым. Необходимо указать список столбцов, в которых проихзводить исправления значений\")\n",
    "            \n",
    "        if strategy not in ['dict', 'func']:\n",
    "            raise ValueError(\"strategy должен быть 'dict' - для исправления значений по словарю, или 'func' - для определния метода вручную снаружи, например, lambda x: x * 10\")\n",
    "\n",
    "        self.values_dict = values_dict or {}\n",
    "        self.columns = columns\n",
    "        self.func = func\n",
    "        self.strategy = strategy\n",
    "    \n",
    "\n",
    "    def fit(self, X: pd.DataFrame, y: None = None):\n",
    "        \"\"\"Формальное объявление (не требует обучения)\"\"\"\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X: pd.DataFrame, y: None = None) -> pd.DataFrame:\n",
    "        \"\"\"Исправляет ошибки в данных\"\"\"\n",
    "        print('- Выполняю исправление ошибок')\n",
    "\n",
    "        df = X.copy()\n",
    "        \n",
    "        for col in self.columns:\n",
    "            if col not in df.columns:\n",
    "                print(f\"Столбец {col} не найден в данных, пропускаю\\n\")\n",
    "                continue\n",
    "\n",
    "            if self.strategy == 'func' and self.func is not None:\n",
    "                try:\n",
    "                    df[col] = df[col].apply(self.func)\n",
    "                    print(f'- Исправил значения в столбце {col}\\n Пример исправленных данных: \\n {df[col].head(1)}')\n",
    "                except Exception as e:\n",
    "                    raise RuntimeError(f\"Ошибка при применении функции {self.func} к столбцу {col}\")\n",
    "                \n",
    "            elif self.strategy == 'dict' and self.values_dict:\n",
    "                for incorrect_value, correct_value in self.values_dict.items():\n",
    "                    df[col] = df[col].replace(self.values_dict)\n",
    "        return df\n",
    "\n",
    "    def fit_transform(self, X, y: None = None, **fit_params):\n",
    "        return self.fit(X, y).transform(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01f6e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecimalPointChanger(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Класс для замены разделителя дроби в строковых столбцах\"\"\"\n",
    "\n",
    "    def __init__(self, columns: List[str]):\n",
    "        \"\"\"Инициализация заменщика дроби в строковых столбцах\"\"\"\n",
    "        \n",
    "        self.columns = columns  # список столбцов, в которых нужно заменить разделитель дроби\n",
    "    \n",
    "    def fit_transform(self, X: Union[pd.DataFrame, np.array], y: None = None, **fit_params) -> np.ndarray:\n",
    "        \n",
    "        \"\"\"Непосредственно заменяет разделитель дроби запятую на точку\"\"\"\n",
    "        print('- Определяю необходимость замены запятой на точку')\n",
    "        \n",
    "        df = X.copy()\n",
    "\n",
    "        # Если columns не указаны, обрабатываем все столбцы\n",
    "        cols_to_process = self.columns if self.columns else df.columns\n",
    "\n",
    "        for col in cols_to_process:\n",
    "            if col in df.columns:\n",
    "                # Проверяем, есть ли запятые в столбце\n",
    "                if df[col].dtype == 'object' and df[col].str.contains(',').any():\n",
    "                    df[col] = df[col].str.replace(',', '.').astype(float)\n",
    "                    print(f'- Заменил запятую на точку в столбце {col}')\n",
    "                    print(f'--- Значения в столбце {col}: {df[col].unique()}\\n')\n",
    "        \n",
    "        print('- Обработка завершена\\n')\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c46c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OutlierRemover(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Класс для удаления выбросов из данных методом IQR только для train\"\"\"\n",
    "\n",
    "    def __init__(self, columns: List[str] = None, factor=1.5, replace_with_nan=False):\n",
    "        \"\"\"Инициализация удалителя выбросов. Есть возможность указать столбцы, в которых убирать выбросы. По умолчанию размер 1.5 квантиля\"\"\"\n",
    "        self.columns = columns\n",
    "        self.factor = factor\n",
    "        self.replace_with_nan = replace_with_nan\n",
    "        self.bounds_dict = {}\n",
    "\n",
    "    def fit_transform(self, X: pd.DataFrame, y: None = None, name=None, **fit_params) -> pd.DataFrame:\n",
    "        \"\"\"Обучает удалитель выбросов - описывает размер квантилей и границы усов. Удаляет выбросы\"\"\"\n",
    "\n",
    "        if name and 'test' in name:\n",
    "            print(f'- Удаление выбросов не проводится в тестовой выборке {name}, пропускаю шаг.')\n",
    "            return X\n",
    "\n",
    "        print('- Определяю границы выбросов методом IQR')\n",
    "        \n",
    "        df_transformed = X.copy()\n",
    "\n",
    "        cols_to_process = self.columns if self.columns else df_transformed.select_dtypes(include=[np.number]).columns\n",
    "        \n",
    "        # Проверка на наличие выбросов\n",
    "        outlier_cols = []\n",
    "        for col in cols_to_process:\n",
    "            if col in df_transformed.columns:\n",
    "                Q1 = df_transformed[col].quantile(0.25)\n",
    "                Q3 = df_transformed[col].quantile(0.75)\n",
    "                IQR = Q3 - Q1\n",
    "                lower_bound = Q1 - self.factor * IQR\n",
    "                upper_bound = Q3 + self.factor * IQR\n",
    "                self.bounds_dict[col] = (lower_bound, upper_bound)\n",
    "                \n",
    "                outliers = (df_transformed[col] < lower_bound) | (df_transformed[col] > upper_bound)\n",
    "                if outliers.any():\n",
    "                    outlier_cols.append(col)\n",
    "        \n",
    "        if not outlier_cols:\n",
    "            print('- Выбросы не обнаружены')\n",
    "            return df_transformed\n",
    "        \n",
    "        print(f'- Обнаружены выбросы в столбцах: {outlier_cols}')\n",
    "        \n",
    "        # Показ боксплотов для столбцов с выбросами\n",
    "        n_cols = len(outlier_cols)\n",
    "        fig, axes = plt.subplots(1, n_cols, figsize=(5*n_cols, 4))\n",
    "        if n_cols == 1:\n",
    "            axes = [axes]\n",
    "        \n",
    "        for i, col in enumerate(outlier_cols):\n",
    "            lower_bound, upper_bound = self.bounds_dict[col]\n",
    "            print(f'Нормальные пределы для {col}: [{lower_bound:.2f} - {upper_bound:.2f}]')\n",
    "            sns.boxplot(y=df_transformed[col], ax=axes[i])\n",
    "            axes[i].set_title(f'Выбросы в {col}')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Обработка выбросов\n",
    "        if self.replace_with_nan:\n",
    "            print('- Заменяю выбросы на NaN\\n')\n",
    "            for col, (lower_bound, upper_bound) in self.bounds_dict.items():\n",
    "                if col in df_transformed.columns:\n",
    "                    outliers = (df_transformed[col] < lower_bound) | (df_transformed[col] > upper_bound)\n",
    "                    df_transformed.loc[outliers, col] = np.nan\n",
    "        else:\n",
    "            print('- Выполняю удаление выбросов\\n')\n",
    "            for col, (lower_bound, upper_bound) in self.bounds_dict.items():\n",
    "                if col in df_transformed.columns:\n",
    "                    outliers = (df_transformed[col] < lower_bound) | (df_transformed[col] > upper_bound)\n",
    "                    df_transformed = df_transformed[~outliers]\n",
    "                \n",
    "        return df_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbdd2836",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImplicitDuplicatesViewer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Выводит уникальные значения каждого столбца для визуального определения неявных дубликатов\"\"\"\n",
    "\n",
    "    def __init__(self, columns: List[str] = None):\n",
    "        \"\"\"Инициализация определеителя неявных дуликатов\"\"\"\n",
    "        self.columns = columns\n",
    "\n",
    "\n",
    "    def fit(self, X: pd.DataFrame, y: None = None):\n",
    "        return self\n",
    "\n",
    "\n",
    "    def transform(self, X: pd.DataFrame, y: None = None):\n",
    "        \"\"\"Выводит уникальные значения каждого столбца для визуального определения неявных дуликатов\"\"\"\n",
    "\n",
    "        print('- Выполняю поиск неявных дубликатов в нечисловых столбцах')\n",
    "\n",
    "        df = X.copy()\n",
    "\n",
    "        if self.columns:\n",
    "            for col in self.columns:\n",
    "                if col in df.columns:\n",
    "                    print(f'- Уникальные значения в столбце {col}: {X[col].unique()}\\n')\n",
    "            return X\n",
    "        else: \n",
    "            # columns = X.select_dtypes(exclude=[np.number]).columns # проверить только нечисловвые ячейки\n",
    "            for col in df.columns:\n",
    "                print(f'- Уникальные значения в столбце {col}: {X[col].unique()}\\n')\n",
    "            return X\n",
    "        \n",
    "    def fit_transform(self, X, y: None = None, **fit_params):\n",
    "        return self.fit(X, y).transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a2fb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DuplicateRemover(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Класс для удаления дубликатов\"\"\"\n",
    "\n",
    "    def __init__(self, columns: List[str] = None):\n",
    "        \"\"\"Инициализация удалителя дубликатов\"\"\"\n",
    "        self.columns = columns\n",
    "\n",
    "    def fit(self, X: pd.DataFrame, y: None = None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X: pd.DataFrame, y: None = None):\n",
    "        \"\"\"Удаляет дубликаты\"\"\"\n",
    "\n",
    "        duplicate_count = X.duplicated().sum()\n",
    "\n",
    "        if duplicate_count:\n",
    "            print(f'- Выявлено {duplicate_count} дубликатов')\n",
    "            print('- Выполняю удаление дубликатов\\n')\n",
    "\n",
    "            if self.columns:\n",
    "                df = X.drop_duplicates(subset=self.columns)                \n",
    "            else:\n",
    "                df = X.drop_duplicates()\n",
    "            \n",
    "            remaining_duplicates = X.duplicated().sum()\n",
    "            print(f'- Осталось {remaining_duplicates} дубликатов\\n')\n",
    "\n",
    "        else:\n",
    "            print('- Дубликатов не выявлено\\n')\n",
    "        return X\n",
    "            \n",
    "    \n",
    "    def fit_transform(self, X, y: None = None, **fit_params):\n",
    "        return self.fit(X, y).transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f66ef67",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MissingValueHandler(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Класс для обработки пропущенных значений в данных. Возможные варианты параметра strategy: mean, median, mode, drop. По умолчанию drop\"\"\"\n",
    "\n",
    "    def __init__(self, strategy='mean', fill_value=None):\n",
    "        \"\"\"Инициализация обработчика пропущенных значений. По умолчанию заполняет средним значением.\n",
    "        \"\"\"\n",
    "        self.strategy = strategy\n",
    "        self.fill_value = fill_value\n",
    "        self.fill_values_ = {}  # для хранения значений для заполнения\n",
    "\n",
    "    def fit(self, X: pd.DataFrame, y: None=None):\n",
    "        \"\"\"Формальное объявление\"\"\"\n",
    "        return self\n",
    "        \n",
    "    def transform(self, X: pd.DataFrame, y: None = None, **fit_params):\n",
    "        \"\"\"Заполняет пропущенные значения или удаляет строки в тестовой выборке. режимы: mean, median, mode, drop\"\"\"\n",
    "        \n",
    "        df = X.copy()\n",
    "        \n",
    "        if self.strategy == 'mean':\n",
    "            self.fill_values_ = df.select_dtypes(include=[np.number]).mean().to_dict() # словарь средних значений для каждого числового столбца\n",
    "\n",
    "        elif self.strategy == 'median':\n",
    "            self.fill_values_ = df.select_dtypes(include=[np.number]).median().to_dict()\n",
    "\n",
    "        elif self.strategy == 'mode':\n",
    "            self.fill_values_ = {}\n",
    "            for col in df.columns:\n",
    "                self.fill_values_[col] = df[col].value_counts().index[0]\n",
    "\n",
    "        elif self.strategy == 'drop':\n",
    "            null_count = df.isna().sum().sum()\n",
    "            if null_count > 0 or df.eq(\" \").any().any():\n",
    "                print('- Нашел пропуски в данных\\n')\n",
    "                null_string_count = len(df[df.isna().any(axis=1)])\n",
    "                display(df[df.isna().any(axis=1)])\n",
    "                if len(df[df.eq(\" \").any(axis=1)]) != 0:\n",
    "                    display(df[df.eq(\" \").any(axis=1)])\n",
    "                \n",
    "                null_string_percentage = null_string_count / len(df) * 100\n",
    "                if null_string_percentage < 10:\n",
    "                    print(f'- Выявлено {null_count} пропусков в {null_string_count} строках, что составляет {null_string_percentage:.2f}% от таблицы.  Выполняю удаление строк с пропущенными значениями\\n')\n",
    "                    df = df.dropna()\n",
    "                    df = df[~df.eq(\" \").any(axis=1)]  # удаляет пустые пробелы типа пропуск\n",
    "                    if df.isna().sum().sum() == 0:\n",
    "                        print('- Пропусков не осталось.\\n')\n",
    "                    else:\n",
    "                        print(f'- {df.isna().sum().sum()} пропусков осталось.\\n')\n",
    "                    return df\n",
    "            else:\n",
    "                print('- Пропусков не найдено\\n')\n",
    "\n",
    "        for col, fill_value in self.fill_values_.items():\n",
    "             if col in df.columns:\n",
    "                if df[col].isnull().sum() > 0:\n",
    "                    print(f'- В колонке {col} {df[col].isnull().sum()} пропусков. Заполняю пропуски на {self.strategy}\\n')\n",
    "                    df[col] = df[col].fillna(fill_value)\n",
    "\n",
    "        return df\n",
    "\n",
    "    def fit_transform(self, X: pd.DataFrame, y: None = None, **fit_params):\n",
    "        return self.fit(X, y).transform(X)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7383a738",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColumnRemover(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Удаляет лишние колонки, переданные в списке\"\"\" \n",
    "\n",
    "    def __init__(self, columns: List[str]):\n",
    "        self.columns = columns\n",
    "\n",
    "    def fit(self, X: pd.DataFrame, y: None=None):\n",
    "        # Просто сохраняем информацию о столбцах для удаления\n",
    "        return self\n",
    "\n",
    "    def transform(self, X: pd.DataFrame):\n",
    "\n",
    "        df = X.copy()\n",
    "\n",
    "        for col in self.columns:\n",
    "            if col in df.columns:\n",
    "                df = df.drop(col, axis=1)\n",
    "                print(f'- Удалил столбец {col}')\n",
    "        return df\n",
    "\n",
    "    def fit_transform(self, X: pd.DataFrame, y: None=None, **fit_params):\n",
    "        return self.fit(X, y).transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6724518",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FloatToIntChanger(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Преобразует дробные значения в целочисленные (режим Multiplie - по умолчанию: \n",
    "    умножает на 100 и сохраняет как Int, simple: без умножения меняет тип) на основе переданного списка столбцов\n",
    "    \"\"\"    \n",
    "\n",
    "    def __init__(self, columns, strategy):\n",
    "        self.columns = columns\n",
    "        self.strategy = strategy\n",
    "\n",
    "\n",
    "    def fit(self, X: pd.DataFrame, y=None):\n",
    "        # Просто сохраняем информацию о столбцах формально\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            self.feature_names_in_ = X.columns.tolist()\n",
    "        else:\n",
    "            # Если на входе массив, генерируем имена колонок\n",
    "            self.feature_names_in_ = [f\"col_{i}\" for i in range(X.shape[1])]\n",
    "        return self\n",
    "    \n",
    "\n",
    "    def transform(self, X: pd.DataFrame):\n",
    "\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            df = X.copy()\n",
    "        else:\n",
    "            # Восстанавливаем DataFrame из массива\n",
    "            df = pd.DataFrame(X, columns=self.feature_names_in_)\n",
    "\n",
    "        if self.strategy == 'simple':\n",
    "            for col in self.columns:\n",
    "                if col in df.columns:\n",
    "                    print(f'\\n - Меняю тип на int столбце {col}')\n",
    "                    df = df[col].astype('int')\n",
    "            return df\n",
    "\n",
    "        if self.strategy == 'multiplie':\n",
    "            for col in self.columns:\n",
    "                if col in df.columns:\n",
    "                    print(f'\\n - Значения в столбце {col} умножаю на 100 ')\n",
    "                    df[col] = (df[col] * 100).astype('int')\n",
    "                else:\n",
    "                    print(f'- Колонка {col} не найдена в данных')\n",
    "            return df\n",
    "\n",
    "    def fit_transform(self, X: pd.DataFrame, y=None, **fit_params):\n",
    "        return self.fit(X, y).transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226af4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EDAPreprocessor:\n",
    "    \"\"\"\n",
    "    Основной класс пайплайна для предобработки данных\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, func: Callable[..., Any] | None = None):\n",
    "        self.steps = []  # список шагов предобработки, которые будут выполняться в пайплайне\n",
    "        self.fitted_transformers = {}  # для хранения обученных трансформеров (запоминает что-то и делает)\n",
    "        \n",
    "    def add_mistake_corrector(\n",
    "                                self, \n",
    "                                columns: List[str] | None = None,\n",
    "                                values_dict: dict | None = None, \n",
    "                                func: Callable[..., Any] | None = None, \n",
    "                                strategy: str | None = None, \n",
    "                                step_name: str =' Преобразование некорректных данных'):\n",
    "        \"\"\"Добавляет шаг исправления ошибок в препроцессор, принимает на вход список колонок, в которых произвести замены, словарь с неверными и верными значениями\"\"\"\n",
    "        \n",
    "        mistake_corrector = MistakeCorrector(\n",
    "                                                columns=columns, \n",
    "                                                values_dict=values_dict, \n",
    "                                                func=func,\n",
    "                                                strategy=strategy\n",
    "            )\n",
    "        self.steps.append((step_name, mistake_corrector))\n",
    "        return self\n",
    "\n",
    "    def add_column_remover(\n",
    "            self, \n",
    "            columns: List[str], \n",
    "            step_name: str = 'Удаление столбцов'):\n",
    "        \n",
    "        column_remover=ColumnRemover(columns)\n",
    "        self.steps.append((step_name, column_remover))\n",
    "        return self\n",
    "\n",
    "    def add_float_to_int_changer(\n",
    "            self, \n",
    "            columns:List[str] | None = None,\n",
    "            strategy='multiplie', \n",
    "            step_name='Преобразование дробных чисел в целочисленное'):\n",
    "        float_to_int_changer=FloatToIntChanger(columns, strategy)\n",
    "        self.steps.append((step_name, float_to_int_changer))\n",
    "        return self\n",
    "\n",
    "    def add_decimal_point_changer(\n",
    "            self, \n",
    "            columns:List[str] | None = None, \n",
    "            step_name='Замена запятой на точку в дробных числах при необходимости'):\n",
    "        decimal_point_changer = DecimalPointChanger(columns)\n",
    "        self.steps.append((step_name, decimal_point_changer))\n",
    "        return self\n",
    "\n",
    "\n",
    "    def add_missing_value_handler(\n",
    "            self, \n",
    "            strategy='drop', \n",
    "            fill_value=None, \n",
    "            step_name='Проверка пропущенных значений'):\n",
    "        \"\"\"Добавляет обработчик пропущенных значений в препроцессор\"\"\"\n",
    "        missing_handler = MissingValueHandler(strategy=strategy, fill_value=fill_value)\n",
    "        self.steps.append((step_name, missing_handler))\n",
    "        return self    \n",
    "\n",
    "\n",
    "    def add_outlier_remover(\n",
    "            self, \n",
    "            columns:List[str] | None = None, \n",
    "            factor=1.5, \n",
    "            replace_with_nan=False,\n",
    "            step_name='Проверка на наличие выбросов'):\n",
    "        '''Добавляет шаг удаления выбросов в препроцессор только для train'''\n",
    "        outlier_remover = OutlierRemover(columns=columns, factor=factor, replace_with_nan=replace_with_nan)\n",
    "        self.steps.append((step_name, outlier_remover))\n",
    "        return self\n",
    " \n",
    "    \n",
    "    def add_drop_duplicates(\n",
    "            self, \n",
    "            step_name='Проверка на наличие явных дубликатов'):\n",
    "        \"\"\"Добавляет шаг удаления дуликатов\"\"\"\n",
    "        duplicate_remover = DuplicateRemover()\n",
    "        self.steps.append((step_name, duplicate_remover))\n",
    "        return self\n",
    "    \n",
    "\n",
    "    def add_implicit_duplicates_viewer(\n",
    "            self, \n",
    "            columns:List[str] | None = None, \n",
    "            step_name='Отображение неявных дубликатов и проверка на неоднородность данных'):\n",
    "        \"\"\"Добавляет шаг отображения уникальных значений каждого столбца для выявления неявных дуликатов визуально.\"\"\"\n",
    "        implict_duplicates_viewer = ImplicitDuplicatesViewer(columns=columns)\n",
    "        self.steps.append((step_name, implict_duplicates_viewer))\n",
    "        return self\n",
    "    \n",
    "\n",
    "    def add_custom_transformer(self, step_name: str, transformer):\n",
    "        \"\"\"Добавляет пользовательский трансформер в пайплан предобраотки\"\"\"\n",
    "        self.steps.append((step_name, transformer))\n",
    "        return self\n",
    "    \n",
    "\n",
    "    def fit_transform(self, X: pd.DataFrame, name, y: None=None):\n",
    "        \"\"\"Обучает все трансформеры пайплайна (запоминает единые параметры и условия исполнения - консистентность). Принимает df и целевую переменную опционально.\"\"\"\n",
    "\n",
    "        df = X.copy()\n",
    "\n",
    "        for i, (step_name, transformer) in enumerate(self.steps):\n",
    "            print(f'\\nИсполнение шага {i+1}: {step_name}')\n",
    "            df = transformer.fit_transform(df, name=name)\n",
    "            self.fitted_transformers[step_name] = transformer\n",
    "\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46747bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "EDA_Preprocessor_pipeline = (\n",
    "    EDAPreprocessor()  \n",
    "    .add_column_remover(columns=['DateCrawled', 'DateCreated', 'LastSeen', 'NumberOfPictures', 'PostalCode'])\n",
    "    .add_mistake_corrector(columns=numeric_columns_list, strategy='func', func=lambda x: x * 10)\n",
    "    .add_decimal_point_changer()        # проверяет наличие запятой в дробном чисе если найдет заменит на точку\n",
    "    .add_outlier_remover(\n",
    "        # replace_with_nan=True\n",
    "        # columns=['Age', 'Sleep Hours Per Day', 'Income', 'Exercise Hours Per Week']\n",
    "        )    # удаляет выбросы только в определенных столбцах, тестовую выборку пропустит\n",
    "    .add_missing_value_handler(strategy='median')        # Обработка пропусков\n",
    "    .add_drop_duplicates()              # проверяет строки дубликаты\n",
    "    .add_implicit_duplicates_viewer(columns=None)   # выводит уникальные значения для определения неявных дуликатов\n",
    "    \n",
    "    # .add_float_to_int_changer(strategy='multiplie', columns=['Age', 'Heart Rate', 'Exercise Hours Per Week', 'Physical Activity Days Per Week', 'Sleep Hours Per Day'])\n",
    ")\n",
    "\n",
    "print('Вот таким у нас получился предобработчик данных.\\n')\n",
    "\n",
    "print(\"Шаги в пайплайне:\\n\")\n",
    "for i, (name, step) in enumerate(EDA_Preprocessor_pipeline.steps):\n",
    "    print(f\"{i+1}. {name}: {step}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97608832",
   "metadata": {},
   "source": [
    "### **3.5. Классификация признаков по типам**\n",
    "\n",
    "Перед построением распределений признаков и обучений модели необходимо классифицировать их по способу обработки, а не по математической классификации: \n",
    "\n",
    "- **числовые**, \n",
    "- **категориальные**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af73b5f4",
   "metadata": {},
   "source": [
    "**1. Числовые** — используются как есть:\n",
    "\n",
    "- `RegistrationYear` — непрерывный\n",
    "\n",
    "- `Power` — непрерывный\n",
    "\n",
    "- `Kilometer` — дискретный (но обрабатывается как непрерывный)\n",
    "\n",
    "- `RegistrationMonth` — дискретный\n",
    "\n",
    "- `PostalCode` — числовой (но может быть категориальным, регион влияет на цену, но 99к уникальных значений, можно агрегировать)\n",
    "\n",
    "**2. Категориальные** — требуют кодирования:\n",
    "\n",
    "- `VehicleType` — номинальный (sedan, suv, coupe...)\n",
    "\n",
    "- `Gearbox` — номинальный (manual, auto)\n",
    "\n",
    "- `Model` — номинальный (golf, passat...)\n",
    "\n",
    "- `FuelType` — номинальный (petrol, diesel...)\n",
    "\n",
    "- `Brand` — номинальный (volkswagen, audi...)\n",
    "\n",
    "- `Repaired` — бинарный (yes/no)\n",
    "\n",
    "**Обработка:**\n",
    "\n",
    "`LinearRegression`: OneHotEncoder (создает бинарные столбцы)\n",
    "\n",
    "`LightGBM`: OrdinalEncoder или передать как categorical_feature (LightGBM сам обработает)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7195f32e",
   "metadata": {},
   "source": [
    "Разделим признаки на группы:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31912775",
   "metadata": {},
   "source": [
    "## **3.6. Оценка распределения признаков**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373e8926",
   "metadata": {},
   "source": [
    "Распределение показывает, как предобработать данные и какие трансформации применить перед обучением модели.\n",
    "\n",
    "Зачем смотреть распределение признаков:\n",
    "\n",
    "**1. Выявление аномалий и выбросов**\n",
    "\n",
    "- `Цена` = 0€ или Power = 20000 л.с. — явные ошибки\n",
    "\n",
    "- `Год` = 1000 или 9999 — нереальные значения\n",
    "\n",
    "**2. Выбор метода обработки**\n",
    "\n",
    "- Нормальное распределение → StandardScaler для LinearRegression\n",
    "\n",
    "- Скошенное распределение → логарифмирование или RobustScaler\n",
    "\n",
    "- Равномерное → MinMaxScaler\n",
    "\n",
    "**3. Понимание данных**\n",
    "\n",
    "- Если 75% `Kilometer` = 150000 → признак малоинформативен (ограничение платформы)\n",
    "\n",
    "- Если `Price` сильно скошен вправо → много дешевых авто, мало дорогих\n",
    "\n",
    "**4. Выбор признаков**\n",
    "\n",
    "- Бимодальное распределение → возможно, есть скрытые группы (премиум/эконом)\n",
    "\n",
    "**5. Трансформации для модели**\n",
    "\n",
    "- `LinearRegression` чувствительна к масштабу → нужна нормализация\n",
    "\n",
    "- Логарифм цены может улучшить предсказание (если распределение логнормальное)\n",
    "\n",
    "**6. Проверка качества данных**\n",
    "\n",
    "- Все значения округлены до 5000? → данные агрегированы\n",
    "\n",
    "- Пики на определенных значениях? → возможно, заполнение пропусков константой"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a1570f",
   "metadata": {},
   "source": [
    "### **3.6.1. Распределение бинарных признаков**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d66293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Визуализация бинарных признаков: столбчатая диаграмма с двумя цветами и процентами\n",
    "df['Repaired'].value_counts(normalize=True).plot.barh()\n",
    "plt.title('Распределение: Repaired (%)')\n",
    "plt.xlabel('Доля')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672d00c4",
   "metadata": {},
   "source": [
    "### **3.6.2. Распределение числовых признаков**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63572d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Распределение числовых признаков\n",
    "numerical_features = ['Price', 'RegistrationYear', 'Power', 'Kilometer', 'RegistrationMonth']\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, col in enumerate(numerical_features):\n",
    "    df[col].hist(bins=50, ax=axes[i], edgecolor='black')\n",
    "    axes[i].set_title(f'Распределение: {col}')\n",
    "    axes[i].set_xlabel(col)\n",
    "    axes[i].set_ylabel('Частота')\n",
    "\n",
    "axes[-1].axis('off')  # Скрыть последний пустой график\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630bfb55",
   "metadata": {},
   "source": [
    "### **3.6.4. Распределение категориальных признаков**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7eb6753",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Визуализация категориальных признаков\n",
    "# Распределение категориальных признаков\n",
    "categorical_features = ['VehicleType', 'Gearbox', 'FuelType', 'Brand', 'Repaired']\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, col in enumerate(categorical_features):\n",
    "    df[col].value_counts().plot.barh(ax=axes[i])\n",
    "    axes[i].set_title(f'Распределение: {col}')\n",
    "    axes[i].set_xlabel('Количество')\n",
    "\n",
    "axes[-1].axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2ac42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Непрерывные признаки для phik_matrix (interval_cols)\n",
    "continuous_features = ['Power']  # только мощность — истинно непрерывная\n",
    "\n",
    "# Или можно добавить:\n",
    "continuous_features = ['Power', 'RegistrationYear']  # если год считать непрерывным"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74401b81",
   "metadata": {},
   "source": [
    "## **3.7. Расшифровка оценки описательной статитистики и распределения значений признаков**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7671fb59",
   "metadata": {},
   "source": [
    "## **3.8. Корреляция данных**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f1034d",
   "metadata": {},
   "outputs": [],
   "source": [
    "interval_cols = feature_types['continuous'] # только дробные числа, или которые не в силах посчитать руками и может иметь друбную часть (если очень много значений, значит интервальный тип)\n",
    "\n",
    "phik_corr = train_df.phik_matrix(interval_cols=interval_cols)\n",
    "phik_corr     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32e6911",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 15))\n",
    "sns.heatmap(phik_corr.round(2), annot=True, cmap='coolwarm')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06a6111",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87460d42",
   "metadata": {},
   "source": [
    "## **3.10. Проверка данных на неоднородность: выявление нелинейных связей**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4d4637",
   "metadata": {},
   "source": [
    "Мы надеемся, что выявление скрытых связей поможет повысить качество обучения."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0eb1be",
   "metadata": {},
   "source": [
    "**Мы применим:**\n",
    "\n",
    "1. **Тесты Левена и Бартлетта** для проверки однородности дисперсий; \n",
    "2. **Simpson's Paradox:** когда общая корреляция и внутри груцппы имеют противопаоложные знаки;\n",
    "3. Группировочный анализ;\n",
    "4. Стабильность корреляций;\n",
    "5. Скрытые кластеры;\n",
    "6. Нелинейные связи;\n",
    "7. Взаимодействия."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d69c01",
   "metadata": {},
   "source": [
    "#### **3.10.1. Тесты Левена и Бартлетта**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9764beeb",
   "metadata": {},
   "source": [
    "Проверим однородность дисперсий. \n",
    "\n",
    "В искусственных данных, дисперсии в двух подгруппах (1/0) будут либо одинаковые либо резко разные."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0ab126",
   "metadata": {},
   "source": [
    "Функция проверяет однородность дисперсий между группами для выявления неоднородности данных.\n",
    "\n",
    "**Что делает:**\n",
    "\n",
    "- Для каждой группирующей колонки (например, Gender, Diabetes) разбивает данные на подгруппы\n",
    "\n",
    "- Для каждого числового признака применяет два статистических теста:\n",
    "\n",
    "- Тест Левена — проверяет равенство дисперсий (устойчив к отклонениям от нормальности)\n",
    "\n",
    "- Тест Бартлетта — также проверяет равенство дисперсий (чувствителен к нормальности распределения)\n",
    "\n",
    "- Возвращает p-значения тестов и флаг heteroscedastic (неоднородность дисперсий), если p < 0.05\n",
    "\n",
    "**Зачем**: Если дисперсии в группах различаются (гетероскедастичность), это указывает на неоднородность данных — разные подгруппы ведут себя по-разному, что может объяснить отсутствие общих корреляций в ваших данных."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63dad7eb",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
